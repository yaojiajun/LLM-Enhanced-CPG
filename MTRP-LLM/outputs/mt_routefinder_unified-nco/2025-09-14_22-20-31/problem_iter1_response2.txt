```python
import torch

def heuristics_v2(current_distance_matrix: torch.Tensor, 
                  delivery_node_demands: torch.Tensor, 
                  current_load: torch.Tensor, 
                  delivery_node_demands_open: torch.Tensor, 
                  current_load_open: torch.Tensor, 
                  time_windows: torch.Tensor, 
                  arrival_times: torch.Tensor, 
                  pickup_node_demands: torch.Tensor, 
                  current_length: torch.Tensor) -> torch.Tensor:
    
    # Create a score matrix initially filled with zeros
    score_matrix = torch.zeros_like(current_distance_matrix)

    # Capacity constraints evaluation: valid visit if demand <= available load
    capacity_ok = (delivery_node_demands.unsqueeze(0) <= current_load.unsqueeze(1)) & \
                  (delivery_node_demands_open.unsqueeze(0) <= current_load_open.unsqueeze(1))
    score_matrix += capacity_ok.float() * 1.0  # Assign positive score where capacity is ok

    # Duration constraints evaluation: valid visit if length <= remaining route duration
    length_ok = (current_length.unsqueeze(1) >= current_distance_matrix)
    score_matrix += length_ok.float() * 1.0  # Assign positive score for valid edges

    # Time window evaluation: valid visit if arrival times fall within allowed windows
    arrival_time_ok = (arrival_times >= time_windows[:, 0].unsqueeze(0)) & \
                      (arrival_times <= time_windows[:, 1].unsqueeze(0))
    score_matrix += arrival_time_ok.float() * 1.0  # Assign positive score if arrival times are valid

    # Incorporation of backhauls: reward would-be pickups if load can accommodate demands
    backhaul_ok = (pickup_node_demands.unsqueeze(0) <= current_load.unsqueeze(1))
    score_matrix += backhaul_ok.float() * 0.5  # Slightly reward feasible pickups
    
    # Score adjustment based on distances, inching towards minimization of distances
    distance_penalty = -current_distance_matrix / 100  # Normalize distances for score management
    score_matrix += distance_penalty
    
    # Enhanced randomness: modify scores with a small random component
    random_adjustment = torch.rand_like(score_matrix) * 0.1  # Small random values
    score_matrix += random_adjustment

    return score_matrix
```
