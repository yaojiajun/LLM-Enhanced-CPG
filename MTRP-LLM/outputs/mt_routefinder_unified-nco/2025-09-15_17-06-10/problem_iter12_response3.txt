```python
import torch

def heuristics_v2(current_distance_matrix: torch.Tensor, delivery_node_demands: torch.Tensor, current_load: torch.Tensor, 
                  delivery_node_demands_open: torch.Tensor, current_load_open: torch.Tensor, 
                  time_windows: torch.Tensor, arrival_times: torch.Tensor, 
                  pickup_node_demands: torch.Tensor, current_length: torch.Tensor) -> torch.Tensor:
    
    # Normalize the current distance matrix to [0, 1]
    normalized_distance = current_distance_matrix / (torch.max(current_distance_matrix) + 1e-6)

    # Score components
    rand_weights1 = torch.rand_like(normalized_distance)
    rand_weights2 = torch.rand_like(normalized_distance)
    
    # Non-linear activation functions
    score1 = torch.sigmoid(normalized_distance) * rand_weights1                     # Favor shorter distances
    score2 = torch.tanh(torch.relu(current_distance_matrix)) + rand_weights2       # Penalizing longer distances exponentially
    
    # Penalty Terms for Constraints
    capacity_penalty = torch.where(delivery_node_demands > current_load.unsqueeze(1), 
                                    torch.tensor(-1e3, device=current_distance_matrix.device), 
                                    torch.tensor(0.0, device=current_distance_matrix.device))
    
    time_penalty = torch.where((arrival_times + current_distance_matrix > time_windows[:, 1].unsqueeze(0)), 
                                torch.tensor(-1e3, device=current_distance_matrix.device), 
                                torch.tensor(0.0, device=current_distance_matrix.device))

    # Length constraint
    length_penalty = torch.where(current_length.unsqueeze(1) < normalized_distance, 
                                  torch.tensor(-1e3, device=current_distance_matrix.device), 
                                  torch.tensor(0.0, device=current_distance_matrix.device))
    
    # Combined scoring
    heuristic_scores = score1 - score2 + capacity_penalty + time_penalty + length_penalty
    
    # Adding adaptive randomness
    adaptive_randomness = torch.rand_like(heuristic_scores) * 0.5  # Modulates exploration
    heuristic_scores += adaptive_randomness
    
    return heuristic_scores
```
