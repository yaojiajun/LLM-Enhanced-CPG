```python
import torch

def heuristics_v2(current_distance_matrix: torch.Tensor, 
                  delivery_node_demands: torch.Tensor, 
                  current_load: torch.Tensor, 
                  delivery_node_demands_open: torch.Tensor, 
                  current_load_open: torch.Tensor, 
                  time_windows: torch.Tensor, 
                  arrival_times: torch.Tensor, 
                  pickup_node_demands: torch.Tensor, 
                  current_length: torch.Tensor) -> torch.Tensor:

    epsilon = 1e-8
    pomo_size, N_plus_1 = current_distance_matrix.shape

    # Calculate effective capacities and arrival time windows
    effective_capacity = current_load.unsqueeze(1) - delivery_node_demands.unsqueeze(0) + epsilon
    effective_capacity_open = current_load_open.unsqueeze(1) - delivery_node_demands_open.unsqueeze(0) + epsilon

    # Time window constraints
    time_window_insatisfiability = (arrival_times.unsqueeze(2) < time_windows[:, 0].unsqueeze(0).unsqueeze(1)) | (arrival_times.unsqueeze(2) > time_windows[:, 1].unsqueeze(0).unsqueeze(1))
    
    # Penalize transitions that violate time windows and vehicle capacities
    capacity_penalty = ~(effective_capacity >= 0) & time_window_insatisfiability
    open_route_penalty = ~(effective_capacity_open >= 0) & time_window_insatisfiability

    # Filling adjacency scores with penalty values
    heuristic_scores = -torch.inf * torch.ones_like(current_distance_matrix, dtype=torch.float32)

    # Set achievable routes with controlled randomness for acceptance into the heuristic scores
    heuristic_scores[~capacity_penalty] = current_distance_matrix[~capacity_penalty]\
                                           - (torch.rand_like(current_distance_matrix[~capacity_penalty]) * 0.1)
                  
    heuristic_scores[~open_route_penalty] = torch.max(heuristic_scores[~open_route_penalty], 
                                                        current_distance_matrix[~open_route_penalty] 
                                                        - (torch.rand_like(current_distance_matrix[~open_route_penalty]) * 0.1))

    # Ensure only finite values
    finite_mask = torch.isfinite(heuristic_scores)
    heuristic_scores[~finite_mask] = -torch.inf

    return heuristic_scores
```
