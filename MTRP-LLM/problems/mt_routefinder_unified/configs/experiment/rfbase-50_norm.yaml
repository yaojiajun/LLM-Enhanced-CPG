# @package _global_


######################################################################
# NOTE: do not use this directly, as it is the base config
######################################################################

# Override defaults: take configs from relative path
defaults:
  - override /model: routefinder.yaml
  - override /env: mtvrp.yaml
  - override /callbacks: default.yaml
  - override /trainer: default.yaml
  # - override /logger: null # comment this line to enable logging
  - override /logger: wandb.yaml

seed: 69420

env:
  generator_params:
    num_loc: 50
    variant_preset: "all" # NOTE: original is "single_feat", but we use all in our setting

  val_file: [cvrp/val/50.npz, ovrp/val/50.npz, ovrpb/val/50.npz, ovrpbl/val/50.npz,
             ovrpbltw/val/50.npz, ovrpbtw/val/50.npz, ovrpl/val/50.npz, ovrpltw/val/50.npz,
             ovrptw/val/50.npz, vrpb/val/50.npz, vrpl/val/50.npz, vrpbltw/val/50.npz,
             vrpbtw/val/50.npz, vrpbl/val/50.npz, vrpltw/val/50.npz, vrptw/val/50.npz,
             cvrp/val/100.npz, vrptw/val/100.npz, # generalization
  ]

  val_dataloader_names: [cvrp50, ovrp50, ovrpb50, ovrpbl50,
                         ovrpbltw50, ovrpbtw50, ovrpl50, ovrpltw50,
                         ovrptw50, vrpb50, vrpl50, vrpbltw50,
                         vrpbtw50, vrpbl50, vrpltw50, vrptw50,
                         cvrp100, vrptw100]

  test_file: [cvrp/test/50.npz, ovrp/test/50.npz, ovrpb/test/50.npz, ovrpbl/test/50.npz,
              ovrpbltw/test/50.npz, ovrpbtw/test/50.npz, ovrpl/test/50.npz, ovrpltw/test/50.npz,
              ovrptw/test/50.npz, vrpb/test/50.npz, vrpl/test/50.npz, vrpbltw/test/50.npz,
              vrpbtw/test/50.npz, vrpbl/test/50.npz, vrpltw/test/50.npz, vrptw/test/50.npz,
              cvrp/test/100.npz, vrptw/test/100.npz, # generalization
  ]

  test_dataloader_names: ${env.val_dataloader_names}


# Logging: we use Wandb in this case
logger:
  wandb:
    project: "routefinder"
    tags: ["rfbase", "${env.name}"]
    group: "${env.generator_params.variant_preset}-${env.generator_params.num_loc}"
    name: "rfbase"

# Note that we use 100k per epoch, so total is 1000 epochs instead of 10k
# However, due to resource constraints (and time), we consider training to 100 epochs
# https://github.com/FeiLiu36/MTNCO/blob/c5b3b2b8158a2262cc61238b26041ece1594e7e7/MTPOMO/POMO/train_n100.py#L66
model:
  batch_size: 256
  # note: batch size is a list corresponding to num of datasets
  val_batch_size: 128
  test_batch_size: ${model.val_batch_size}
  train_data_size: 100_000
  # note: data size is a list corresponding to num of datasets
  val_data_size: 64
  test_data_size: 64 # NOTE: unused if provided by env
  optimizer_kwargs:
    lr: 3e-4 # NOTE: we will be using 3e-4 from now on
    weight_decay: 1e-6
  lr_scheduler:
    "MultiStepLR"
  lr_scheduler_kwargs:
    milestones: [270, 295]
    gamma: 0.1

trainer:
  # max_epochs: 1000 (full run as per the paper)
  max_epochs: 300 #100 # 100 epochs ~ 8hrs on 1x3090, so we allow 24 hrs

# Easier default under logs/ directory
callbacks:
  model_checkpoint:
    dirpath: logs/${logger.wandb.name}/${now:%Y-%m-%d}_${now:%H-%M-%S}/checkpoints
    monitor: "val/reward/cvrp50"
