_target_: utils.llm_client.llama_api.LlamaAPIClient

# Using llama api. See the available models at https://docs.llama-api.com/quickstart#available-models
model: llama3-70b
temperature: 1.0  # temperature for chat completion
api_key: ${oc.env:LLAMA_API_KEY,null}
base_url: https://api.llama-api.com